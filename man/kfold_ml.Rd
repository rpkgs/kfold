% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kford_ml.R
\name{kfold_ml}
\alias{kfold_ml}
\alias{kfold_rf}
\alias{kfold_xgboost}
\alias{kfold_lm}
\title{kfold machine learning}
\usage{
kfold_ml(X, Y, kfold = 5, FUN, ...)

kfold_rf(X, Y, kfold = 5, FUN = ranger, ntree = 500, importance = "none", ...)

kfold_xgboost(X, Y, kfold = 5, verbose = FALSE, nrounds = 500, ...)

kfold_lm(X, Y, kfold = 5, ...)
}
\arguments{
\item{...}{Further arguments passed to or from other methods (currently ignored).}

\item{importance}{Variable importance mode, one of 'none', 'impurity', 'impurity_corrected', 'permutation'. The 'impurity' measure is the Gini index for classification, the variance of the responses for regression and the sum of test statistics (see \code{splitrule}) for survival.}

\item{verbose}{Show computation status and estimated runtime.}

\item{nrounds}{max number of boosting iterations.}
}
\description{
kfold machine learning
}
\examples{
set.seed(1)
n <- 100 ; p <- 2
X <- matrix(rnorm(n * p), n, p) # no intercept!
y <- as.matrix(rnorm(n))

## kfold
r_lm  <- kfold_lm(X, y)
r_xgb <- kfold_xgboost(X, y)
# r_rf  <- kfold_rf(X, y)

## 70\%-30\% split
r = kfold_calib(X, y, ratio_valid = 0.7, nrounds=500, verbose=FALSE)
r$gof
}
\seealso{
\code{\link[ranger:ranger]{ranger::ranger()}}, \code{\link[xgboost:xgb.train]{xgboost::xgboost()}}
}
